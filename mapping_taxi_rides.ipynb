{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "import csv\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime, timedelta\r\n",
    "import os\r\n",
    "from time import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "process_start = time()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "file_taxi_rides = \"./data/yellow_tripdata_2014-01/yellow_tripdata_2014-01.csv\"\r\n",
    "file_rides_groupped_hours = \"./data/processing/hours_{0}.csv\"\r\n",
    "file_rides_groupped_days = \"./data/processing/days_{0}.csv\"\r\n",
    "file_rides_groupped_weekdays = \"./data/processing/weekdays_{0}.csv\"\r\n",
    "file_rides_groupped_weather = \"./data/processing/weather_{0}.csv\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def store_groups(filename_template, grouped_df):\r\n",
    "    for group in grouped_df.groups:\r\n",
    "        if isinstance(group, float):\r\n",
    "            group = int(group)\r\n",
    "            \r\n",
    "        tag = group if isinstance(group, int) else group.strftime(\"%Y%m%d_%H\")\r\n",
    "        file_group = filename_template.format(tag)\r\n",
    "        if os.path.exists(file_group):\r\n",
    "            grouped_df.get_group(group).to_csv(file_group, mode='a', header=False, index=False)\r\n",
    "        else:\r\n",
    "            grouped_df.get_group(group).to_csv(file_group, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "file_weather = \"./data/prepared_weather.csv\"\r\n",
    "df_weather = pd.read_csv(file_weather)\r\n",
    "df_weather['datetime'] =  pd.to_datetime(df_weather['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
    "df_weather = df_weather.reset_index().set_index(\"datetime\")\r\n",
    "df_weather = df_weather.drop(\"index\", axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "extrating_columns = [\r\n",
    "        'pickup_datetime',\r\n",
    "        'dropoff_datetime',\r\n",
    "        'passenger_count',\r\n",
    "        'trip_distance',\r\n",
    "        'payment_type',\r\n",
    "        'tip_amount']\r\n",
    "\r\n",
    "chunk_size = 1000000 * 3\r\n",
    "chunks_to_process = None\r\n",
    "count = 0\r\n",
    "for chunk in pd.read_csv(file_taxi_rides, chunksize=chunk_size):\r\n",
    "    start = time()\r\n",
    "\r\n",
    "    columns_trimming = {col:col.strip() for col in chunk.columns}\r\n",
    "    chunk = chunk.rename(columns=columns_trimming)\r\n",
    "\r\n",
    "    # drop not neccessary columns\r\n",
    "\r\n",
    "    columns_to_drop = [col for col in chunk.columns if col not in extrating_columns]\r\n",
    "    chunk = chunk.drop(columns_to_drop, axis=1)\r\n",
    "\r\n",
    "    # prepare for mapping by datetime\r\n",
    "\r\n",
    "    chunk['pickup_datetime'] = pd.to_datetime(chunk['pickup_datetime'], format=\"%Y-%m-%d %H:%M:%S\")\r\n",
    "\r\n",
    "    chunk[\"by_weekday\"] = chunk['pickup_datetime'].apply(lambda t: t.weekday())\r\n",
    "    chunk[\"by_hour\"] = chunk['pickup_datetime'].apply(lambda t: t.replace(second=0, microsecond=0, minute=0))\r\n",
    "    chunk[\"by_day\"] = chunk['pickup_datetime'].apply(lambda t: t.date())\r\n",
    "\r\n",
    "    # join with weather\r\n",
    "\r\n",
    "    chunk[\"datetime\"] = chunk[\"by_hour\"]\r\n",
    "    chunk = chunk.reset_index().set_index(\"datetime\")\r\n",
    "    chunk = chunk.drop(\"index\", axis=1)\r\n",
    "    chunk = chunk.join(df_weather, on=\"datetime\")\r\n",
    "\r\n",
    "    # mapping\r\n",
    "    hourly_groups = chunk.groupby(\"by_hour\")\r\n",
    "    daily_groups = chunk.groupby(\"by_day\")\r\n",
    "    weekly_groups = chunk.groupby(\"by_weekday\")\r\n",
    "    weather_groups = chunk.groupby(\"weather_description_code\")\r\n",
    "\r\n",
    "    store_groups(file_rides_groupped_hours, hourly_groups)\r\n",
    "    store_groups(file_rides_groupped_days, daily_groups)\r\n",
    "    store_groups(file_rides_groupped_weekdays, weekly_groups)\r\n",
    "    store_groups(file_rides_groupped_weather, weather_groups)\r\n",
    "\r\n",
    "    count += 1\r\n",
    "    print(f\"processed {count} chunk in {time()-start} sec\")\r\n",
    "\r\n",
    "    if chunks_to_process is not None and count >= chunks_to_process:\r\n",
    "        break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processed 1 chunk in 301.39654302597046 sec\n",
      "processed 2 chunk in 390.7491683959961 sec\n",
      "processed 3 chunk in 301.82050490379333 sec\n",
      "processed 4 chunk in 302.9894509315491 sec\n",
      "processed 5 chunk in 185.72009801864624 sec\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "print(f\"Done in {time()-process_start} sec\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done in 1525.367035150528 sec\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}